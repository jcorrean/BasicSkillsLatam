[
  {
    "objectID": "SupplementaryMaterial.html",
    "href": "SupplementaryMaterial.html",
    "title": "A Cross-National Comparison Case Study on the Basic Skills Academic Offering",
    "section": "",
    "text": "The codes developed to preprocess the raw data are available in the following GitHub repository. Researchers interested in replicate or reproduce our analysis can find the RProject file BasicSkillsLatam.RProj.\nThe supplementary material is documented as a Quarto document with the name SupplementaryMaterial.qmd and can be rendered in RStudio.\n\n\nRaw data are available as texts (PDF or docx files) in the folder of the corresponding sampled country. For example, sampled documents from Argentina are available in the folder “Argentina,” documents from Brazil are available in the folder “Brazil,” and so on. Texts pre-processing were handled with readtext and quanteda in a series of R scripts. These scripts are available in the folder “Pre-processing.”\n\n\n\nAs a convenient step in our analyses, we created the folder “Curated_Data” which provides curated data for each country. This curated data provides the estimated centrality for each basic skill in each country. Apart from these data, we also provide the NetworkData folder. This second folder contains the academic offering of each nation as a network data serialized in RDS format."
  },
  {
    "objectID": "SupplementaryMaterial.html#network-properties-set-up",
    "href": "SupplementaryMaterial.html#network-properties-set-up",
    "title": "A Cross-National Comparison Case Study on the Basic Skills Academic Offering",
    "section": "2.1 Network properties set up",
    "text": "2.1 Network properties set up\nThe network properties of each nation’s academic offering was done with the network package. The following network attributes are present for each academic offering: country of origin, membership to the Organization for Economic Development (OECD), network size, network density, network clustering (estimated by the reinforcement_tm algortihm available in the tnet package). Vertex attributes include the country of origin (for both node partitions), the length of the brochure (for nodes in the first partition), the degree centrality (for both node partitions), the eigenvector centrality (for both node partitions), the program level (for the first node partition), and the name of each skills (for nodes in the second partition). These vertex attributes enable us to exert statistical control when estimating the network effects in our series of exponential random graph models."
  },
  {
    "objectID": "Second_Webscraper.html",
    "href": "Second_Webscraper.html",
    "title": "A Cross-National Comparison Case Study on the Basic Skills Academic Offering",
    "section": "",
    "text": "exactly in the same way than in the past notebook, if you dont have any of these packages installed, you will need to install them first. cmd command or command terminal ‘pip install name of the package’\nNow, this code is splied into 3 parts: the calling for all the necessary packages. The path setup and the rest of the process. I recomend you tu run each part separately to know if you have any issues and solve them.\n\nimport logging \nimport os \nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait \nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.common.exceptions import TimeoutException\nimport pandas as pd\nimport time\nimport json\nfrom selenium.webdriver.common.keys import Keys\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[1], line 8\n      6 from selenium.webdriver.support import expected_conditions as EC\n      7 from selenium.common.exceptions import TimeoutException\n----&gt; 8 import pandas as pd\n      9 import time\n     10 import json\n\nModuleNotFoundError: No module named 'pandas'\n\n\n\nThese are the paths with the routes to: 1. Path where you located the cvs file with the links. this is the same worked in the previous notebook. 2. Path where you want to download all the files. As a recomendation, I usually save all my files in the “raw data” folder, this in order to push all the files directly to the github repo.\n\ncsv_path = '/home/alrier/Documentos/GitHub/SoftSkillsLatam/Costa_Rica/URLs.csv' #path where you located the cvs file with the links.\nfile_path = '/home/alrier/Documentos/GitHub/SoftSkillsLatam/Costa_Rica/' # path to download the university files.\ndf = pd.read_csv(csv_path)\n\nOnce you have the paths seted up, you can run the following lines.\nThis code will open a google chrome web browser using selenium, will loop through the URL columns in the csv file deined in the first path, then will open each link and look for the keywords = [“Program”, “Master”, “Doctor”, “PhD”, “Ph.D.”]. You can always change it if you consider it necessary. Now, if the code finds any of all of the keywords in the text, then it will print and wownload the document in the second path defined previously.\nthe codu wil create a security copy of the original csv file in the path defined here: new_csv_path = “/home/alrier/Documentos/canada/USA_modified.csv” So, better you change this path to anyone you want.\nAs a setup recomendations, some webpages have javascript interactive buttons. It force the browser to take more time in the process. If you see that the code colapse becouse of the timing: WebDriverWait(driver, 3) –&gt; this is the timer for the code, the only thing you need to do is, modify this variable to the number of seconds you want the code to wait until the browser is ready.\n\n# Chrome options\noptions = webdriver.ChromeOptions()\noptions.add_argument(\"--kiosk-printing\")\nsettings = {\n    \"recentDestinations\": [{\n        \"id\": \"Save as PDF\",\n        \"origin\": \"local\",\n        \"account\": \"\",\n    }],\n    \"selectedDestinationId\": \"Save as PDF\",\n    \"version\": 2\n}\nprefs = {'printing.print_preview_sticky_settings.appState': json.dumps(settings),\n         \"savefile.default_directory\": file_path, }\noptions.add_experimental_option('prefs', prefs)\n# Loop through URLs\nfor index, row in df.iterrows():\n    url = row['URL']\n    driver = webdriver.Chrome(options=options)\n    driver.get(url)\n    try:\n        dynamic_element = WebDriverWait(driver, 3).until(\n            EC.presence_of_element_located((By.XPATH, \"//button[contains(@class,'animated')]\"))\n        )\n        dynamic_element.click()\n        WebDriverWait(driver, 3).until(lambda driver: driver.execute_script('return document.readyState') == 'complete')\n    except:\n        pass\n    keywords = [\"master\", \"Master\", \"MSc\", \"PhD\", \"phd\", \"Doctorado\", \"doctorado\", \"maestría\"]\n    for keyword in keywords:\n        if driver.find_elements(By.XPATH, f\"//*[contains(text(), '{keyword}')]\"):\n            driver.execute_script('window.print();')\n            break\n    driver.quit()\n    # Delete the URL from the csv file after each iteration.\n    df.at[index, 'URL'] = \"\"\n# Save the modified dataframe in a new CSV file\nnew_csv_path = '/home/alrier/Documentos/GitHub/SoftSkillsLatam/Costa_Rica/URLs.csv' \ndf.to_csv(new_csv_path, index=False)\n# Rename each PDF in the \"pdf_files_temp\" folder.\npdf_temp_path = os.path.join(file_path, \"pdf_files_temp\")\nfor file in os.listdir(pdf_temp_path):\n    os.rename(os.path.join(pdf_temp_path, file), os.path.join(file_path, \"USA_\" + file))\n# Delete the \"pdf_files_temp\" after the process is completed.\nos.rmdir(pdf_temp_path)\nprint('Completed!.') #if successfully completed.\n\nCompleted!."
  },
  {
    "objectID": "Borrador/Borrador.html",
    "href": "Borrador/Borrador.html",
    "title": "Skills and Academic Offering in Latin America",
    "section": "",
    "text": "1 Introduction\nA challenging decision for any manager is placing the right person in the right job. In his search for predictors of job performance, the American psychologist David C.McClelland [1] argued that academic aptitude, knowledge from content tests, school grades, and credentials are often poor predictors of employee performance. McClelland’s research laid the groundwork for the ``job competence assessment’’ method, which became foundational to management literature in the latter half of the 20\\(^{th}\\) century [2]. Contemporary data-driven research supports McClelland’s findings, suggesting that academic offerings often fall short of meeting companies’ job requirements [3]. In this context, gaining a competitive advantage from a labor perspective increasingly relies on improving the educational-occupational match [4]. Some scholars argue that one way to enhance this education-job alignment is by estimating the value of employees’ skills, especially given the unpredictable future [5].\nA list\n\nItem 1\nItem 2\n\n\n\n\n\n\n\n\n\nReferences\n\n1. McClelland DC. Testing for competence rather than for “intelligence.” American psychologist. 1973;28: 1. doi:10.1037/h0034092\n\n\n2. Spencer LM, Spencer SM. Competence at Work: Models for Superior Performance. New York: John Wiley & Sons, Inc.; 1993. \n\n\n3. Börner K, Scrivner O, Gallant M, Ma S, Liu X, Chewning K, et al. Skill discrepancies between research, education, and jobs reveal the critical need to supply soft skills for the data economy. Proceedings of the National Academy of Sciences of the United States of America. 2018;115: 12630–12637. doi:10.1073/pnas.1804247115\n\n\n4. Gadár L, Abonyi J. Graph configuration model based evaluation of the education-occupation match. PloS One. 2018;13: e0192427. doi:10.1371/journal.pone.0192427\n\n\n5. Vista A. Data-Driven Identification of Skills for the Future: 21st-Century Skills for the 21st-Century Workforce. Sage Open. 2020;10: 2158244020915904. doi:10.1177/2158244020915904"
  },
  {
    "objectID": "first_geturls.html",
    "href": "first_geturls.html",
    "title": "A Cross-National Comparison Case Study on the Basic Skills Academic Offering",
    "section": "",
    "text": "This is the first part of the code you need to run:\nThe cell below will open a new Google chrome window in which you will need to manually open all the tabs with the information you consider useful.\nIn this new window you will need to open as many tabs as you consider important. Take into consideration that, the more tabs you open, the more memory ram your computer will need to carry on all the process, however between 10 to 20 tabs are ok.\nOnce you have all the tabs opened proceed with the second part of the code.\nNOTE: if you dont have selenium installed, then first. open a console or your CMD command and run $ pip install selenium\n\nI truly recomend to run this code in your local environment. It will surely run in Google colab but you will ned aditional code and configurations.\n\nfrom selenium import webdriver #If you dont have this package installed, possibly you will need to do it.\nimport csv\ncsv_file_path = 'C:/Users/juesg/Desktop/Soft Skills/SoftSkillsLatam/Uruguay/URLs.csv' #Path you have to change to save your urls\ndriver = webdriver.Chrome()\n\nHere you will be able to take each one of these tabs previously opened and automatically copy each URL into a csv file defined in —&gt; csv_file_path = ‘write here your desktop folder’\nTake into consideration to create a column title in the csv file, it has to be “URL” in capital letters. It will be important in the next stage of the process. Aditionally, this code will look for the URL column to paste the links.\nOnce you have all the tabs already opened in the window displayed by the machine, now you can run the follow lines. It should be from here to the end of this notebook.\n\n#It allows you to handle manually all the tabs you previously opened.\ntab_handles = driver.window_handles\ntab_urls = []\nfor handle in tab_handles:\n    driver.switch_to.window(handle)\n    tab_urls.append(driver.current_url) #append links\n    # close the tabs after copied all URLs\n    driver.close()\n# close main window\ndriver.quit()\n# Open csv file in writing mode\nwith open(csv_file_path, 'a', newline='') as csv_file:\n    csv_writer = csv.writer(csv_file)\n    # write the links in the URL column.\n    for url in tab_urls:\n        csv_writer.writerow([url])#If the code shows any error, rewrite the word url in capitals here.\nprint(\"URLs successfully copied to your CSV :) \")\n\nURLs successfully copied to your CSV :)"
  },
  {
    "objectID": "SupplementaryMaterial.html#raw-data-and-pre-processing",
    "href": "SupplementaryMaterial.html#raw-data-and-pre-processing",
    "title": "A Cross-National Comparison Case Study on the Basic Skills Academic Offering",
    "section": "",
    "text": "Raw data are available as texts (PDF or docx files) in the folder of the corresponding sampled country. For example, sampled documents from Argentina are available in the folder “Argentina,” documents from Brazil are available in the folder “Brazil,” and so on. Texts pre-processing were handled with readtext and quanteda in a series of R scripts. These scripts are available in the folder “Pre-processing.”"
  },
  {
    "objectID": "SupplementaryMaterial.html#curated-data",
    "href": "SupplementaryMaterial.html#curated-data",
    "title": "A Cross-National Comparison Case Study on the Basic Skills Academic Offering",
    "section": "",
    "text": "As a convenient step in our analyses, we created the folder “Curated_Data” which provides curated data for each country. This curated data provides the estimated centrality for each basic skill in each country. Apart from these data, we also provide the NetworkData folder. This second folder contains the academic offering of each nation as a network data serialized in RDS format."
  },
  {
    "objectID": "SupplementaryMaterial.html#model-specifications",
    "href": "SupplementaryMaterial.html#model-specifications",
    "title": "A Cross-National Comparison Case Study on the Basic Skills Academic Offering",
    "section": "4.1 Model Specifications",
    "text": "4.1 Model Specifications\nWe begin with the specification of our Model 1\n\n\nCall:\nergm(formula = SampledNetworks ~ edges)\n\nMaximum Likelihood Results:\n\n      Estimate Std. Error MCMC % z value Pr(&gt;|z|)    \nedges -0.91681    0.01161      0  -78.95   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n     Null Deviance: 50378  on 36340  degrees of freedom\n Residual Deviance: 43475  on 36339  degrees of freedom\n \nAIC: 43477  BIC: 43486  (Smaller is better. MC Std. Err. = 0)"
  },
  {
    "objectID": "SupplementaryMaterial.html#hypothesis-and-model-specifications",
    "href": "SupplementaryMaterial.html#hypothesis-and-model-specifications",
    "title": "A Cross-National Comparison Case Study on the Basic Skills Academic Offering",
    "section": "4.1 Hypothesis and Model Specifications",
    "text": "4.1 Hypothesis and Model Specifications\nModel 1: The fundamental hypothesis associated to this model posits that our top five basic skills suffice to account for the connectivity observed above. When each of these skills are modeled as statistical terms, their estimates will be positive, greater than zero, and statistically significant.\n\n\nCall:\nergm(formula = SampledNetworks ~ edges + b2factor(\"vertex.names\", \n    levels = c(8, 9, 2, 4, 1)))\n\nMaximum Likelihood Results:\n\n                                        Estimate Std. Error MCMC % z value\nedges                                   -1.58520    0.01975      0 -80.276\nb2factor.vertex.names.science            3.08692    0.04730      0  65.267\nb2factor.vertex.names.speaking           1.08756    0.03950      0  27.533\nb2factor.vertex.names.active_listening   0.78953    0.04092      0  19.296\nb2factor.vertex.names.learning_strategy  0.76631    0.04106      0  18.664\nb2factor.vertex.names.active_learning    0.15393    0.04645      0   3.314\n                                        Pr(&gt;|z|)    \nedges                                    &lt; 1e-04 ***\nb2factor.vertex.names.science            &lt; 1e-04 ***\nb2factor.vertex.names.speaking           &lt; 1e-04 ***\nb2factor.vertex.names.active_listening   &lt; 1e-04 ***\nb2factor.vertex.names.learning_strategy  &lt; 1e-04 ***\nb2factor.vertex.names.active_learning    0.00092 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n     Null Deviance: 50378  on 36340  degrees of freedom\n Residual Deviance: 37385  on 36334  degrees of freedom\n \nAIC: 37397  BIC: 37448  (Smaller is better. MC Std. Err. = 0)\n\n\nThe results of our first models confirms our expectations regarding the significance of these basic skills for accounting for the network connectivity between programs and basic skills in the Latin American academic offering.\nModel 2: This model is an extension of the previous one and compares the robustness of our top five basic skills against the length of the brochure that is used to promote the programs where these skills are explicitly mentioned. The length of the brochure is a covariate that can hide confounding factors associated to the skills targeted by the programs. To prevent biased estimates of our five basic skills, we need to clarify if this covariate alters the estimates reported in model 1. We expect that the statistical estimates for our five basic skills will remain positive, greater than zero, and statistically significant, while the statistical estimate for the brochure length will remain non-significant and close to zero.\n\n\nCall:\nergm(formula = SampledNetworks ~ edges + b2factor(\"vertex.names\", \n    levels = c(8, 9, 2, 4, 1)) + b1cov(\"Brochure.Length\"))\n\nMaximum Likelihood Results:\n\n                                          Estimate Std. Error MCMC % z value\nedges                                   -1.682e+00  2.064e-02      0 -81.497\nb2factor.vertex.names.science            3.114e+00  4.746e-02      0  65.614\nb2factor.vertex.names.speaking           1.103e+00  3.977e-02      0  27.743\nb2factor.vertex.names.active_listening   8.018e-01  4.122e-02      0  19.454\nb2factor.vertex.names.learning_strategy  7.783e-01  4.136e-02      0  18.818\nb2factor.vertex.names.active_learning    1.567e-01  4.685e-02      0   3.344\nb1cov.Brochure.Length                    6.034e-05  3.347e-06      0  18.026\n                                        Pr(&gt;|z|)    \nedges                                    &lt; 1e-04 ***\nb2factor.vertex.names.science            &lt; 1e-04 ***\nb2factor.vertex.names.speaking           &lt; 1e-04 ***\nb2factor.vertex.names.active_listening   &lt; 1e-04 ***\nb2factor.vertex.names.learning_strategy  &lt; 1e-04 ***\nb2factor.vertex.names.active_learning   0.000826 ***\nb1cov.Brochure.Length                    &lt; 1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n     Null Deviance: 50378  on 36340  degrees of freedom\n Residual Deviance: 36905  on 36333  degrees of freedom\n \nAIC: 36919  BIC: 36979  (Smaller is better. MC Std. Err. = 0)\n\n\nThe hypothesis proposed in model 2 is partially confirmed. The statistical estimates for our top five skills remained almost invariant, while the estimate for the length of the brochure is close to zero albeit statistically significant.\nModel 3: The f"
  }
]